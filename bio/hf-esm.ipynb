{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "\n",
    "tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval().to(device)\n",
    "print(f\"Putting Model in eval mode on {device}\")\n",
    "\n",
    "print(f\"Tokenizer tokenizer.vocab_size {tokenizer.vocab_size}\")\n",
    "print(f\"Tokenizer tokenizer.max_model_input_sizes {tokenizer.max_model_input_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Protein:\n",
    "    name: str\n",
    "    filename: str\n",
    "    link: str\n",
    "    format: str\n",
    "    seq: str = field(init=False)\n",
    "    len: int = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.seq = \"\".join([str(res.seq) for res in SeqIO.parse(self.filename, self.format)])\n",
    "        self.len = len(self.seq)\n",
    "\n",
    "# Proteins we will compare\n",
    "proteins = [\n",
    "    Protein(\"1JHF\", \"1jhf.pdb\", \"https://www.rcsb.org/structure/1JHF\", \"pdb-atom\"),\n",
    "    Protein(\"3LS4\", \"3ls4.pdb\", \"https://www.rcsb.org/structure/3LS4\", \"pdb-atom\"),\n",
    "    Protein(\"1K6F\", \"1k6f.cif\", \"https://www.rcsb.org/structure/1K6F\", \"cif-atom\"),\n",
    "    Protein(\"5XR8\", \"5xr8.pdb\", \"https://www.rcsb.org/structure/5XR8\", \"pdb-atom\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# input_protein = str(proteins[0][1])\n",
    "# print(f\"Input protein is {input_protein}\")\n",
    "# print(f\"Input protein length {len(input_protein)}\")\n",
    "# print(f\"Input protein count {Counter(input_protein)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(input_protein, return_tensors=\"pt\")\n",
    "# inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "# inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "\n",
    "# print(f\"Inputs {inputs}\")\n",
    "# print(f\"Inputs input_ids shape {inputs['input_ids'].shape}\")\n",
    "# print(f\"Inputs input_ids device {inputs['input_ids'].device}\")\n",
    "# print(f\"Inputs input_ids type {type(inputs['input_ids'])}\")\n",
    "# print(f\"Inputs attention_mask shape {inputs['attention_mask'].shape}\")\n",
    "# print(f\"Inputs attention_mask device {inputs['attention_mask'].device}\")\n",
    "# print(f\"Inputs attention_mask type {type(inputs['attention_mask'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([protein.seq for protein in proteins], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "\n",
    "# print(f\"Inputs input_ids {inputs['input_ids']}\")\n",
    "print(f\"Inputs input_ids shape {inputs['input_ids'].shape}\")\n",
    "print(f\"Inputs input_ids device {inputs['input_ids'].device}\")\n",
    "print(f\"Inputs input_ids type {type(inputs['input_ids'])}\")\n",
    "\n",
    "# print(f\"Inputs attention_mask {inputs['attention_mask']}\")\n",
    "print(f\"Inputs attention_mask shape {inputs['attention_mask'].shape}\")\n",
    "print(f\"Inputs attention_mask device {inputs['attention_mask'].device}\")\n",
    "print(f\"Inputs attention_mask type {type(inputs['attention_mask'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "# embedding = outputs.last_hidden_state\n",
    "embedding = outputs.pooler_output\n",
    "\n",
    "# print(f\"Embedding {embedding}\")\n",
    "print(f\"Embedding type {type(embedding)}\")\n",
    "print(f\"Embedding shape {embedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between our embeddings\n",
    "\n",
    "for iA, proteinA in enumerate(proteins):\n",
    "    print(\"\\n\")\n",
    "    for iB, proteinB in enumerate(proteins):\n",
    "        \n",
    "        _ = torch.nn.CosineSimilarity(dim = 0)(embedding[iA, :], embedding[iB, :])\n",
    "        print(f\"CosineSimilarity between {proteinA.name} and {proteinB.name} is {_}\")\n",
    "        \n",
    "        _ = torch.nn.PairwiseDistance()(embedding[iA, :], embedding[iB, :])\n",
    "        print(f\"PairwiseDistance between {proteinA.name} and {proteinB.name} is {_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('esm-protein')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82e226f6589d1ab3e1f42304a181bda372a94ed1a47ab6deafb50839d437363a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
